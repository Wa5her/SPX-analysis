{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file gets information on historic quarterly reports for all companies listed in the SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loadsthe CIK values from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/jy5jnx1j7w12x8wpwfsn9n6m0000gq/T/ipykernel_35200/1669742426.py:6: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# URL of the Wikipedia page\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "# Read the tables on the Wikipedia page\n",
    "response = requests.get(wiki_url)\n",
    "tables = pd.read_html(response.text)\n",
    "\n",
    "# The first table on the page contains the S&P 500 companies\n",
    "sp500_table = tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code gets JSON files with historic 10 Q filings for all items in the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading files from SEC\n",
    "def download_file(url=\"https://www.sec.gov/include/ticker.txt\", filename=\"CIK.tsv\", user_agent=\"Michelle LiuWatts admin@hercompany.com\"):\n",
    "    headers = {\"User-Agent\": user_agent}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    sleep(0.101)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return f\"File downloaded successfully as {filename}\"\n",
    "    else:\n",
    "        return f\"Failed to download file: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 15 new files, 488 files already existed, and 0 files failed to download\n"
     ]
    }
   ],
   "source": [
    "new = exist = failed = 0\n",
    "for i, row in sp500_table.iterrows():\n",
    "    cik = str(row['CIK']).zfill(10)\n",
    "    ticker = row['Symbol']\n",
    "    save_dir = \"qtrly-data\"\n",
    "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    \n",
    "    filepath = os.path.join(os.getcwd(),save_dir, f\"{ticker}.json\")\n",
    "    if not os.path.exists(filepath):\n",
    "        result = download_file(url, filepath)\n",
    "        new = new + 1\n",
    "    else:\n",
    "        result = f\"{ticker} already downloaded\"\n",
    "        exist = exist + 1\n",
    "        # print(result)\n",
    "    if \"Failed\" in result:\n",
    "        print(f\"{ticker} failed to download\")\n",
    "        failed = failed + 1\n",
    "print(f\"Downloaded {new} new files, {exist} files already existed, and {\n",
    "      failed} files failed to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to extract data from the saved Jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics and their units as in the sec json files\n",
    "eps_metrics = {\n",
    "    \"EarningsPerShareDiluted\": \"USD/shares\",\n",
    "    \"IncomeLossFromContinuingOperationsPerDilutedShare\": \"USD/shares\",\n",
    "    \"IncomeLossFromDiscontinuedOperationsNetOfTaxPerDilutedShare\": \"USD/shares\",\n",
    "    \"WeightedAverageNumberOfDilutedSharesOutstanding\": \"shares\",\n",
    "    \"NetIncomeLoss\": \"USD\",\n",
    "    \"NetIncomeLossFromContinuingOperationsAvailableToCommonShareholdersDiluted\": \"USD\",\n",
    "    \"NetIncomeLossFromDiscontinuedOperationsAvailableToCommonShareholdersDiluted\": \"USD\"\n",
    "\n",
    "}\n",
    "# Save to JSON file\n",
    "with open('metrics_to_extract.json', 'w') as json_file:\n",
    "    json.dump(eps_metrics, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from JSON file\n",
    "with open('metrics_to_extract.json', 'r') as json_file:\n",
    "    eps_metrics = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_metrics(metrics_and_units, directory=\"./sec_data\"):\n",
    "    \"\"\"\n",
    "    Extracts specified metrics and their units from JSON files in the current directory.\n",
    "\n",
    "    Args:\n",
    "        metrics_and_units: A dictionary where keys are metric names \n",
    "                           and values are their corresponding units.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # current_directory = os.getcwd()\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            ticker = os.path.splitext(filename)[0]\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    json_data = json.load(file)\n",
    "                    us_gaap_elements = json_data.get(\n",
    "                        'facts', {}).get('us-gaap', {})\n",
    "\n",
    "                    for metric, unit in metrics_and_units.items():\n",
    "                        metric_data = us_gaap_elements.get(\n",
    "                            metric, {}).get('units', {})\n",
    "                        if unit in metric_data:\n",
    "                            for entry in metric_data[unit]:\n",
    "                                entry_data = {\n",
    "                                    'ticker': ticker, 'metric': metric}\n",
    "                                entry_data.update(entry)\n",
    "                                data.append(entry_data)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data using the defined metrics\n",
    "extract_metrics(eps_metrics,'qtrly-data').to_csv(\"EPS_fact.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"EPS_fact.csv\")\n",
    "\n",
    "\n",
    "def days_between_dates(date1_str, date2_str, date_format=\"%Y-%m-%d\"):\n",
    "    if pd.isnull(date1_str) or pd.isnull(date2_str):\n",
    "        return None\n",
    "    date1 = datetime.strptime(date1_str, date_format)\n",
    "    date2 = datetime.strptime(date2_str, date_format)\n",
    "    delta = date2 - date1\n",
    "    return abs(delta.days)\n",
    "\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['period_days'] = df.apply(lambda row: days_between_dates(\n",
    "    row['start'], row['end']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to create a line per event to track price changees across all spx stocks due to that event\n",
    "An event can be:\n",
    "1. declaration of quarterly reports of a SPX stock\n",
    "2. interest rate changes \n",
    "3. declaration of economic indicator reports \n",
    "4. news ?? (unknown now)\n",
    "how is this useful ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPX-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
