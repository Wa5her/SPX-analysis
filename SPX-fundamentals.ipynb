{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file gets information on historic quarterly reports for all companies listed in the SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loadsthe CIK values from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the Wikipedia page\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "# Read the tables on the Wikipedia page\n",
    "tables = pd.read_html(wiki_url)\n",
    "\n",
    "# The first table on the page contains the S&P 500 companies\n",
    "sp500_table = tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code gets JSON files with historic 10 Q filings for all items in the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading files from SEC\n",
    "def download_file(url=\"https://www.sec.gov/include/ticker.txt\", filename=\"CIK.tsv\", user_agent=\"Michelle LiuWatts admin@hercompany.com\"):\n",
    "    headers = {\"User-Agent\": user_agent}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    sleep(0.101)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return f\"File downloaded successfully as {filename}\"\n",
    "    else:\n",
    "        return f\"Failed to download file: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 new files, 503 files already existed, and 0 files failed to download\n"
     ]
    }
   ],
   "source": [
    "new = exist = failed = 0\n",
    "for i, row in sp500_table.iterrows():\n",
    "    cik = str(row['CIK']).zfill(10)\n",
    "    ticker = row['Symbol']\n",
    "    save_dir = \"sec_data\"\n",
    "    url = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    if not os.path.exists(f\"{save_dir}/{ticker}.json\"):\n",
    "        result = download_file(url, f\"{save_dir}/{ticker}.json\")\n",
    "        new = new + 1\n",
    "    else:\n",
    "        result = f\"{ticker} already downloaded\"\n",
    "        exist = exist + 1\n",
    "        # print(result)\n",
    "    if \"Failed\" in result:\n",
    "        print(f\"{ticker} failed to download\")\n",
    "        failed = failed + 1\n",
    "print(f\"Downloaded {new} new files, {exist} files already existed, and {\n",
    "      failed} files failed to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to extract data from the saved Jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics and their units as in the sec json files\n",
    "eps_metrics = {\n",
    "    \"EarningsPerShareDiluted\": \"USD/shares\",\n",
    "    \"IncomeLossFromContinuingOperationsPerDilutedShare\": \"USD/shares\",\n",
    "    \"IncomeLossFromDiscontinuedOperationsNetOfTaxPerDilutedShare\": \"USD/shares\",\n",
    "    \"WeightedAverageNumberOfDilutedSharesOutstanding\": \"shares\",\n",
    "    \"NetIncomeLoss\": \"USD\",\n",
    "    \"NetIncomeLossFromContinuingOperationsAvailableToCommonShareholdersDiluted\": \"USD\",\n",
    "    \"NetIncomeLossFromDiscontinuedOperationsAvailableToCommonShareholdersDiluted\": \"USD\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_metrics(metrics_and_units, directory=\"./sec_data\"):\n",
    "    \"\"\"\n",
    "    Extracts specified metrics and their units from JSON files in the current directory.\n",
    "\n",
    "    Args:\n",
    "        metrics_and_units: A dictionary where keys are metric names \n",
    "                           and values are their corresponding units.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # current_directory = os.getcwd()\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            ticker = os.path.splitext(filename)[0]\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    json_data = json.load(file)\n",
    "                    us_gaap_elements = json_data.get(\n",
    "                        'facts', {}).get('us-gaap', {})\n",
    "\n",
    "                    for metric, unit in metrics_and_units.items():\n",
    "                        metric_data = us_gaap_elements.get(\n",
    "                            metric, {}).get('units', {})\n",
    "                        if unit in metric_data:\n",
    "                            for entry in metric_data[unit]:\n",
    "                                entry_data = {\n",
    "                                    'ticker': ticker, 'metric': metric}\n",
    "                                entry_data.update(entry)\n",
    "                                data.append(entry_data)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000002289B8E6FF0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Eshwar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\", line 1535, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# Extract data using the defined metrics\n",
    "extract_metrics(eps_metrics).to_csv(\"EPS_fact.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"EPS_fact.csv\")\n",
    "\n",
    "\n",
    "def days_between_dates(date1_str, date2_str, date_format=\"%Y-%m-%d\"):\n",
    "    if pd.isnull(date1_str) or pd.isnull(date2_str):\n",
    "        return None\n",
    "    date1 = datetime.strptime(date1_str, date_format)\n",
    "    date2 = datetime.strptime(date2_str, date_format)\n",
    "    delta = date2 - date1\n",
    "    return abs(delta.days)\n",
    "\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['period_days'] = df.apply(lambda row: days_between_dates(\n",
    "    row['start'], row['end']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to create a line per event to track price changees across all spx stocks due to that event\n",
    "An event can be:\n",
    "1. declaration of quarterly reports of a SPX stock\n",
    "2. interest rate changes \n",
    "3. declaration of economic indicator reports \n",
    "4. news ?? (unknown now)\n",
    "how is this useful ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
