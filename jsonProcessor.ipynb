{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code collects a dictionary of all lables and their descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  metrics  \\\n",
      "0                                  AccountsPayableCurrent   \n",
      "1                            AccountsReceivableNetCurrent   \n",
      "2                AccrualForEnvironmentalLossContingencies   \n",
      "3       AccrualForEnvironmentalLossContingenciesDiscou...   \n",
      "4           AccrualForEnvironmentalLossContingenciesGross   \n",
      "...                                                   ...   \n",
      "275278             RestructuringReserveAccrualAdjustment1   \n",
      "275279  AssetsOfDisposalGroupIncludingDiscontinuedOper...   \n",
      "275280  DisposalGroupIncludingDiscontinuedOperationCon...   \n",
      "275281                      FinanceLeasePrincipalPayments   \n",
      "275282  LiabilitiesOfDisposalGroupIncludingDiscontinue...   \n",
      "\n",
      "                                                    label  \\\n",
      "0                               Accounts Payable, Current   \n",
      "1       Accounts Receivable, after Allowance for Credi...   \n",
      "2            Accrual for Environmental Loss Contingencies   \n",
      "3       Accrual for Environmental Loss Contingencies, ...   \n",
      "4       Accrual for Environmental Loss Contingencies, ...   \n",
      "...                                                   ...   \n",
      "275278          Restructuring Reserve, Accrual Adjustment   \n",
      "275279  Disposal Group, Including Discontinued Operati...   \n",
      "275280  Disposal Group, Including Discontinued Operati...   \n",
      "275281                  Finance Lease, Principal Payments   \n",
      "275282  Disposal Group, Including Discontinued Operati...   \n",
      "\n",
      "                                              description  \n",
      "0       Carrying value as of the balance sheet date of...  \n",
      "1       Amount, after allowance for credit loss, of ri...  \n",
      "2       Total costs accrued as of the balance sheet da...  \n",
      "3       Rate applied to the undiscounted amount of env...  \n",
      "4       Undiscounted amount of the accrual for environ...  \n",
      "...                                                   ...  \n",
      "275278  Amount of expense (reversal of expense) which ...  \n",
      "275279  Amount classified as assets attributable to di...  \n",
      "275280  Amount of consideration received or receivable...  \n",
      "275281  Amount of cash outflow for principal payment o...  \n",
      "275282  Amount classified as liabilities attributable ...  \n",
      "\n",
      "[275283 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_us_gaap_elements():\n",
    "    data = []\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    # Loop through all files in the current directory\n",
    "    for filename in os.listdir(current_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(current_directory, filename)\n",
    "\n",
    "            # Open and parse the JSON file\n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    json_data = json.load(file)\n",
    "                    us_gaap_elements = json_data.get(\n",
    "                        'facts', {}).get('us-gaap', {})\n",
    "\n",
    "                    # Extract relevant fields\n",
    "                    for metric, details in us_gaap_elements.items():\n",
    "                        label = details.get('label', '')\n",
    "                        description = details.get('description', '')\n",
    "                        data.append(\n",
    "                            {'metrics': metric, 'label': label, 'description': description})\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Remove duplicates\n",
    "    # df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "df = extract_us_gaap_elements()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('us_gaap_elements.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "LiabilitiesAndStockholdersEquity                                       488\n",
      "NetCashProvidedByUsedInInvestingActivities                             488\n",
      "NetCashProvidedByUsedInFinancingActivities                             488\n",
      "Assets                                                                 488\n",
      "NetCashProvidedByUsedInOperatingActivities                             485\n",
      "                                                                      ... \n",
      "DebtSecuritiesRealizedGainLossExcludingOtherThanTemporaryImpairment      1\n",
      "ContractReceivableRetainageDueInNextRollingTwelveMonths                  1\n",
      "BillingsInExcessOfCostNoncurrent                                         1\n",
      "OtherRevenueExpenseFromRealEstateOperations                              1\n",
      "SubsequentEventEffectOfChangeInTaxStatus                                 1\n",
      "Name: count, Length: 8336, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.read_csv('us_gaap_elements.csv')\n",
    "metric_counts = metrics_df['metrics'].value_counts()\n",
    "\n",
    "\n",
    "print(metric_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to collect \n",
    "income statement\n",
    "    Ops\n",
    "        AccumulatedOtherComprehensiveIncomeLossNetOfTax\n",
    "    WeightedAverageNumberOfDilutedSharesOutstanding\t\n",
    "    EarningsPerShareDiluted\t\n",
    "Balance Sheet\n",
    "    Assets\n",
    "    LiabilitiesAndStockholdersEquity \n",
    "Cashflow statement\n",
    "    NetCashProvidedByUsedInFinancingActivities       \n",
    "    NetCashProvidedByUsedInInvestingActivities   \n",
    "    NetCashProvidedByUsedInOperatingActivities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to extract diluted EPS from all files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_metrics(metrics_and_units):\n",
    "    \"\"\"\n",
    "    Extracts specified metrics and their units from JSON files in the current directory.\n",
    "\n",
    "    Args:\n",
    "        metrics_and_units: A dictionary where keys are metric names \n",
    "                           and values are their corresponding units.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the extracted data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    for filename in os.listdir(current_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(current_directory, filename)\n",
    "            ticker = os.path.splitext(filename)[0]\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    json_data = json.load(file)\n",
    "                    us_gaap_elements = json_data.get(\n",
    "                        'facts', {}).get('us-gaap', {})\n",
    "\n",
    "                    for metric, unit in metrics_and_units.items():\n",
    "                        metric_data = us_gaap_elements.get(\n",
    "                            metric, {}).get('units', {})\n",
    "                        if unit in metric_data:\n",
    "                            for entry in metric_data[unit]:\n",
    "                                entry_data = {\n",
    "                                    'ticker': ticker, 'metric': metric}\n",
    "                                entry_data.update(entry)\n",
    "                                data.append(entry_data)\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Define metrics and their units\n",
    "metrics_and_units = {\n",
    "    \"EarningsPerShareDiluted\": \"USD/shares\",\n",
    "    \"IncomeLossFromContinuingOperationsPerDilutedShare\": \"USD/shares\",\n",
    "    \"IncomeLossFromDiscontinuedOperationsNetOfTaxPerDilutedShare\": \"USD/shares\",\n",
    "    \"WeightedAverageNumberOfDilutedSharesOutstanding\": \"shares\",\n",
    "    \"NetIncomeLoss\": \"USD\",\n",
    "    \"NetIncomeLossFromContinuingOperationsAvailableToCommonShareholdersDiluted\": \"USD\",\n",
    "    \"NetIncomeLossFromDiscontinuedOperationsAvailableToCommonShareholdersDiluted\": \"USD\"\n",
    "\n",
    "}\n",
    "\n",
    "# Extract data using the defined metrics\n",
    "df = extract_metrics(metrics_and_units)\n",
    "df.to_csv('financial_metrics_extract.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('financial_metrics_extract.csv')\n",
    "# this code makes the metrics into columns. the filed sorting is to remove duplicates more than anything\n",
    "pivot_df = df.sort_values(by='filed', ascending=False).pivot_table(index=['ticker', 'start', 'end',\n",
    "                                                                          'form', 'filed'], columns='metric', values='val', aggfunc='first').reset_index()\n",
    "# print(pivot_df.head())\n",
    "\n",
    "# to do list\n",
    "# build logic from the parameters by ETL\n",
    "# get a robust data set where there is only one entry per period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zl/jy5jnx1j7w12x8wpwfsn9n6m0000gq/T/ipykernel_2510/2134367526.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  group_df = pivot_df.groupby(['ticker', 'start', 'end'],group_keys=False).apply(get_latest_non_null_row).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# This code will group by ticker, start, and end, and get only one valid row per period (the latest non-null row)\n",
    "# Function to get the latest non-null row\n",
    "def get_latest_non_null_row(group):\n",
    "    return group.dropna(subset=['filed']).sort_values(by='filed', ascending=False).iloc[0]\n",
    "\n",
    "\n",
    "# Group by ticker, start, and end, then apply the function\n",
    "group_df = pivot_df.groupby(['ticker', 'start', 'end'], group_keys=False).apply(\n",
    "    get_latest_non_null_row).reset_index(drop=True)\n",
    "\n",
    "# print(group_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code aims to eliminiate missing EPS values\n",
    "# Function to calculate the sum while ignoring NaN values\n",
    "def fill_eps(row):\n",
    "    if pd.isna(row['EarningsPerShareDiluted']):\n",
    "        return row[['IncomeLossFromContinuingOperationsPerDilutedShare', 'IncomeLossFromDiscontinuedOperationsNetOfTaxPerDilutedShare']].sum(skipna=True)\n",
    "    return row['EarningsPerShareDiluted']\n",
    "\n",
    "\n",
    "# Apply the function to fill missing EPSdiluted values\n",
    "group_df['EarningsPerShareDiluted'] = group_df.apply(fill_eps, axis=1)\n",
    "try:\n",
    "    group_df.drop(columns=['IncomeLossFromContinuingOperationsPerDilutedShare',\n",
    "                  'IncomeLossFromDiscontinuedOperationsNetOfTaxPerDilutedShare'], inplace=True)\n",
    "except KeyError:\n",
    "    print(\"Columns already dropped\")\n",
    "eps_df = group_df[['ticker', 'start', 'end',\n",
    "                   'form', 'filed', 'EarningsPerShareDiluted']]\n",
    "eps_df.to_csv('eps_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
